import re
import numpy as np
import matplotlib.pyplot as plt

# ── 1)  paste your raw console output below ────────────────────────────────
raw = """
1 0.01506428972203609 0.3743539756775976
2 0.014999974108994374 0.3738881560931656
3 0.014953344032220008 0.3742788316733964
4 0.01501708073393789 0.3743567168143094
5 0.01502704931985087 0.37435894222419547
6 0.015023847782817984 0.3738036941731841
7 0.014969262188608258 0.3735409116409571
8 0.014776875515098478 0.37217790402747514
9 0.014636855061610799 0.3716828872309318
10 0.014405242779420088 0.3699521179780447
11 0.014203882279367317 0.36606959676775325
12 0.01406746155465988 0.3641746608894518
13 0.014012287606312084 0.3616976632031376
14 0.013991836239614884 0.3601705373066741
15 0.01393048543937955 0.3568494509385257
16 0.013827276870763466 0.35448386659474634
17 0.013867810774660351 0.35312844071861954
18 0.013741697899339444 0.35066758933838554
19 0.01366718897802596 0.34808514536730073
20 0.013794662709761804 0.34749577044218716
21 0.013720835667149123 0.3432396349128155
22 0.013740639777948222 0.3426712579220301
23 0.013701851996202514 0.3412749209341404
24 0.013469805776873825 0.3377970715685974
25 0.013444543567334707 0.3354460609984474
26 0.013063004201678552 0.3293740931331492
27 0.012748256330576064 0.3265691117317184
28 0.0126873954315521 0.32288931019410605
29 0.012830114702347373 0.32321457664450914
30 0.012867353437306557 0.32320796711130173
31 0.012957307217440464 0.32244496827241226
32 0.012775445246313393 0.32109737846257147
33 0.012860504029497186 0.32100077687727985
34 0.012826496858930517 0.3214217439618472
35 0.012896924559841169 0.3205308575040298
36 0.0128529591929533 0.3203673956038887
37 0.012833855492946748 0.31969936091019785
38 0.012860547692733386 0.3193176093359397
39 0.012827782592654784 0.3195691991394682
40 0.012930659243105967 0.3193756551567811
41 0.012890466790654472 0.3195311204386355
42 0.012922301973697902 0.31900735009262426
43 0.012878203955201206 0.3188642689502925
44 0.012910950628397205 0.3194666697721191
45 0.01287841602080263 0.3180712155134087
46 0.01291507420216621 0.31757476264726436
47 0.012850940228192975 0.3176275626802818
48 0.01279527399492337 0.3167634192306856
49 0.012931121718064476 0.3188837047680463
50 0.012891697663946051 0.31758550121693513
51 0.012872972495886975 0.31695502376509455
52 0.012958782234665487 0.3179413430884242
53 0.01285901794258008 0.31698952526965696
54 0.012820504736366416 0.3163852844462687
55 0.012825474219581417 0.317043350584035
56 0.012868569923535094 0.3170456264480727
57 0.012926767075629206 0.3177824984346709
58 0.012850518253062385 0.3162869771570921
59 0.012899117754353285 0.3172580034934891
60 0.012940519386527068 0.31758888821562875
61 0.012877741180429404 0.3164808618847472
62 0.012871979509019705 0.3172560779187417
63 0.012906894138315616 0.31738346328740724
64 0.012796476498588867 0.31616103010292324
65 0.012921614316658458 0.31650826200019466
66 0.012930065409488338 0.3183253109774005
67 0.012800462779038789 0.3161502030143584
68 0.012882337603443414 0.3170586632922752
69 0.012917862833335125 0.31734047826853307
70 0.012906315147686101 0.31647766754541695
71 0.012910940632413673 0.31747974711350424
72 0.01284996331584025 0.3159531092069274
73 0.012819081256866764 0.31547232305083084
74 0.012926824444017791 0.3173410178458296
75 0.012889390635203331 0.3169859704114292
76 0.01289598696485326 0.31686177937858867
77 0.01290439444915217 0.31642711846468075
78 0.012853141687572602 0.31482654559516066
79 0.012883617186836227 0.3162522522160878
80 0.012861202515972218 0.31599307332392135
81 0.01288099823144894 0.31675224863610224
82 0.01289257526950309 0.3171466006010351
83 0.012867426462525335 0.31653903654536475
84 0.012888426922089604 0.31646199962175336
85 0.012965349721700986 0.3172170847068188
86 0.012926740394726336 0.3152572571873258
87 0.012897066037435087 0.3159188350896555
88 0.01283844944223699 0.31502641222669436
89 0.012868530111552076 0.315437407398104
90 0.012928808873185583 0.3164728177703408
91 0.012873186096534752 0.3150392393213141
92 0.012618777936728406 0.3112336699779287
93 0.01263706641448704 0.31154291794172895
94 0.012702636625983142 0.31260998408690593
95 0.01256007610965886 0.30970180697805677
96 0.01265676983438912 0.31105477469425896
97 0.012597635270475967 0.3103140132419859
98 0.012607548129271175 0.3111660328607642
99 0.01260295434403472 0.310468202625026
100 0.012680169020471161 0.31144499529131914
101 0.012654373659804896 0.31114750634349897
102 0.012667136491952337 0.31183240617969143
103 0.012619916136940124 0.31125814789613426
104 0.012613078866184372 0.31017036424157524
105 0.012634773765875617 0.3110429867062633
106 0.012649011782034134 0.3110150619709696
107 0.012601766837448954 0.3105736365322007
108 0.01261881473274728 0.3110141651280935
109 0.012679127870366902 0.3113739877217294
110 0.012661531474937034 0.311648690244263
111 0.012628861465065179 0.31056946601595603
112 0.012737036284887409 0.31187640442701337
113 0.012595593497618202 0.30999535436011655
114 0.012670696571982993 0.31132910423788673
115 0.012658983690772604 0.3111698018086752
116 0.012704664694470033 0.3117224648005231
117 0.0126060667606475 0.3107710657717691
118 0.012668252886169209 0.3116132267017371
119 0.012607037252630899 0.3103158729788763
120 0.01260518542357839 0.3108746638499712
121 0.012671069454124044 0.3117830330900006
122 0.012632548750636756 0.3105179180095743
123 0.012467004251842736 0.3075951705267866
124 0.012410507660959485 0.3070104397591997
125 0.012498944410826694 0.3074704520788132
126 0.012506137460571706 0.307761591793197
127 0.012508332791819654 0.3080819860720863
128 0.012309319932217278 0.3061160198777052
129 0.01248098455830213 0.30812101942789116
130 0.01247314816855206 0.30706294589210165
131 0.012469215940874532 0.3078616749140968
132 0.012406505699351238 0.3063135355998985
133 0.012482220566194956 0.30768996995292786
134 0.012326467067210068 0.3048263325963958
135 0.012210083753621962 0.3031059087880423
136 0.012278545719296825 0.3044055105639182
137 0.01227469153560189 0.303824376155012
138 0.012289930078884384 0.304501664346312
139 0.012302154719349749 0.30413341614049577
140 0.01232327180779857 0.3048747218391903
141 0.012243870361418519 0.3034118488158845
142 0.012132806765954896 0.30076624362052184
143 0.012139454884468605 0.30102019387336226
144 0.01215445596631768 0.30055580187045355
145 0.012178533441505707 0.301568447766326
146 0.012172432575704013 0.3012054979034328
147 0.012181675148820934 0.3018852549889828
148 0.012121230608741972 0.30086861276200577
149 0.012201790500026883 0.30177736738492716
150 0.012245266108459817 0.30223047907022405
slope = -1.2214540845872535e-05
"""
# ───────────────────────────────────────────────────────────────────────────

# 2) pull out iter#, noise (2nd number)
iters, noise = [], []
for m in re.finditer(r'^\s*(\d+)\s+([\d.]+)', raw, re.M):
    iters.append(int(m.group(1)))
    noise.append(float(m.group(2)))

iters = np.asarray(iters)
noise = np.asarray(noise)

# 3) linear trend
slope, intercept = np.polyfit(iters, noise, 1)

# 4) plot
fig, ax = plt.subplots()
ax.plot(iters, noise, marker='o', markersize=3)
ax.set_xlabel('EM iteration')
ax.set_ylabel('Noise level')
ax.set_title('Noise level during DuoSpec Iterations on Amazon Metadata')
ax.text(0.95, 0.95, f'Slope = {slope:.2e}', transform=ax.transAxes,
    va='top', ha='right')
plt.show()
